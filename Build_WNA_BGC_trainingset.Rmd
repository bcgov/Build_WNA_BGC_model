---
title: "Random Forest Model of Biogeoclimatic Units for Western North America"
author: "William H MacKenzie & Kiri Daust"
date: "22/03/2020"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
Require::Require(c(
  "bcgov/climr@devl", 
  "caret", 
  "clhs", 
  "data.table", 
  "foreach", 
  "ggplot2", 
  "Microsoft365R",
  "randtoolbox", 
  "ranger", 
  "reproducible",
  "sf", 
  "smotefamily", 
  "terra", 
  "themis",
  "tictoc", 
  "tidymodels"
))

options(reproducible.cachePath = "reproducible.cache/")

source("R/utils.R")
# library(climRdev)
# thebb <- c(55.38847, 54.61025, -126.94957, -127.7162)
# dbCon <- data_connect()
# normal <- normal_input_postgis(dbCon = dbCon, bbox = thebb, cache = TRUE)
# remove(normal)
#tidymodels_prefer()
#install.packages ("spThin")
#conflicted::conflict_prefer(name = "spec", winner = "yardstick")
#conflict_prefer("rescale", "scales")

# source("../Build_USA_BEC/_functions/AddVars.R")
# source("../Build_USA_BEC/_functions/removeOutlier.R")
# source("../Build_USA_BEC/_functions/acc_metrix.R")
# cloud_dir <- "F:/OneDrive - Government of BC/CCISSv12/latest_CCISS_tool_files/"

```

# General process
Build a grid of points for WNA and attribute with data from ClimateBC for BC and ClimateNA for rest. A 2km grid seems to provide enough training points for most BGCs. Large non-vegetation land areas are excluded (lakes and glaciers primarily)
There are areas where BGC mapping represents local effects represented by small polygons and these are removed (2km2) or are coast transition areas that are poorly mapped and climte modelled (inland polygons of CWH)
We tested various variable sets - more work could be done here. First only include variables where an ecologically important control could be defined. Variables are removed that are highly correlated in both space and time. Preliminary runs in the modern climate change period (1991-2019) were assessed. Some additional variables that  were removed at this point as the priority effect could not be controlled. Specifically winter temperatures, which strongly differentiate between BGCs in historic models also rise most markedly through time. As there is no way to prioritize growing season variables, the increase in winter temperatures in the modern period then predict vast changes in the SBS which seem unwarranted. Threshold controls of winter temperatures might be more relevant.
Univariate outliers (IQR *1.5) within each BGC are flagged and  training points with any outliers are removed.
All variables are centered and scaled to harmonize the data dispersion which can effect selection in the model.
To 


Points from a 4km hex grid of western north america are generated in R and submitted to ClimateNA to extract annual and seasonal variables for the historic normal period (1961-90) and an ensemble future climate scenario (rcp45 2040-2070). These data sets are combined. Several additional climate variables are generated including several monthly climate sums for precipitation and growing degree days. All other monthly variables are removed. A winter rechange moisture deficit was calculated and summed with the climatic moisture deficit to account for regions that begin the growing season in soil moisture deficit.


```{r}
tic()
wna_bgc <- st_read("D:/CommonTables/BGC_Maps/WNA_BGC_v12_5Apr2022.gpkg")#
#wna_bgc <- st_read("../WNA_BGC/WNA_BGC_v12_5Apr2022.gpkg")
wna_grid <- st_make_grid(wna_bgc, cellsize = 2000, what = "centers") |> st_transform(crs = 4326)
elev <- terra::rast("D:/CommonTables/DEMs/WNA_DEM_SRT_30m.tif") ##I used a 1km DEM - if you have a higher res one could use that
#elev <- rast("C:\\Users\\kdaust\\AppData\\Local/R/cache/R/climRpnw/inputs_pkg/normal/Normal_1961_1990MP/dem/dem2_WNA.nc")
wna_grid2 <- vect(wna_grid)
tmp_elev <- terra::extract(elev,wna_grid2)

coords <- geom(wna_grid2, df = T)
setDT(coords)
coords[,c("part","hole","geom") := NULL]
coords[,elev := tmp_elev[,2]]
coords[,id := seq_along(elev)]
fwrite(coords, "WNA_2km_grid_WHM.csv")
toc()
###236 seconds
###Chunk making sure the extent were matching
# wna_mask <- vect(wna_bgc)
# wna_mask <- project(wna_mask, "EPSG:4326")
#elev <- crs(elev) <- "epsg:4326" 
# dem_crop <- crop(elev, wna_mask, snap="near", mask=FALSE, touches=TRUE, extend=FALSE, filename="D:/CommonTables/DEMs/WNA_DEM_SRT_30m_cropped.tif")

#elev2 <- terra::project(elev, "epsg:3005") ## this projection may not be suitable for all WNA
# pts <- vect(wna_grid)
# tmp_elev <- terra::extract(elev,pts)
# #pts_4326 <- project(pts, "epsg:4326")
# #coords <- geom(pts_4326,df = TRUE)
# coords <- geom(pts,df = TRUE)
# coords <- coords[,c("geom","x","y")]
# coords <- data.table(coords)
# coords[, elev := tmp_elev$WNA_DEM_SRT_30m]
# coords <- coords[!is.na(elev),]
# setnames(coords, c("id","long","lat","elev"))
# fwrite(coords, "WNA_2km_grid.csv")
# toc()
# coords <- fread("WNA_2km_grid.csv")

# wna_bgc <- vect("D:/CommonTables/BGC_maps/WNA_BGC_v12_5Apr2022.gpkg")
# 
# coords <- fread("WNA_2km_grid_WHM.csv")
# pts <- vect(coords, geom=c("long","lat"), crs = "epsg:4326")
# pts <- project(pts, "epsg:3005")
# pts2 <- crop(pts, ext(wna_bgc))
# pts2 <- project(pts2, "epsg:4326")
# 
# coords2 <- geom(pts2, df = T)
# setDT(coords2)
# coords2[,c("part","hole","geom") := NULL]
# coords2[,elev := pts2$elev]
# coords2[,id := seq_along(elev)]
# fwrite(coords2, "WNA_2km_grid_WHM2.csv")
# 
# 
# wna_grid <- st_make_grid(wna_bgc, cellsize = 2000, what = "centers")
# wna_grid <- st_as_sf(wna_grid)
# wna_grid$id <- seq_along(wna_grid)
# grid_bgc <- st_join(wna_grid,wna_bgc)
# elev <- rast("C:\\Users\\kdaust\\AppData\\Local/R/cache/R/climRpnw/inputs_pkg/normal/Normal_1961_1990MP/dem/dem2_WNA.nc") ##I used a 1km DEM - if you have a higher res one could use that
# elev2 <- terra::project(elev, "epsg:3005")

```

```{r}
coords <- fread("//objectstore2.nrs.bcgov/ffec/CCISS_Working/WNA_BGC/WNA_2km_grid_WHM.csv")
coords <- coords[!is.na(elev),]
coords_sf <- st_as_sf(coords, coords = c("x","y"), crs = 4326)
coords_sf$elev <- NULL
coords_sf <- st_transform(coords_sf, 3005)

bgcs <- st_read("//objectstore2.nrs.bcgov/ffec/CCISS_Working/WNA_BGC/WNA_BGC_v12_5Apr2022.gpkg")

## based on vs_final below
vars_needed <- c("DD5","DD_0_at","DD_0_wt","PPT05","PPT06","PPT07","PPT08","PPT09","CMD","PPT_at","PPT_wt","CMD07","SHM", "AHM", "NFFD", "PAS", "CMI")

clim_vars <- getClimate(coords, bgcs,
                        which_normal = "normal_composite", return_normal = TRUE, 
                        vars = vars_needed, cache = TRUE) |>
  Cache(.)
```


Create different model variable sets
v1=all
v2 = no months
v3 = Biological Variables
vs5 = 16var
vs8 = 35 var
vs9 = reduced 35 for biologial variable reduction to 19
vs10+ = testing effects and final set

```{r create variable sets}
vs_final <- c("DD5", "DD_delayed",
              "PPT_MJ", "PPT_JAS", 
              "CMD.total", "CMI", "CMDMax",
              "SHM", "AHM", "NFFD", "PAS")

```


```{r reduce variables}
addVars(clim_vars)
X_train <- clim_vars[, .SD, .SDcols = c("BGC", vs_final)]
X_train <- X_train[complete.cases(X_train)]

BGC_counts <- X_train[, .(Num = .N), by = .(BGC)]
```


The preprocessing function from the caret package was used to identify variables with near-zero variance or correlation >0.90 in the combined data set. These variables were removed leaving a final variable set of 20 variables.
```

```{r remove poor BGCs}
badbgcs <- c("BWBSvk", "ICHmc1a", "MHun", "SBSun", "ESSFun", "SWBvk","MSdm3","ESSFdc3", "IDFdxx_WY", "MSabS", "FGff", "JPWmk_WY" )#, "ESSFab""CWHws2", "CWHwm", "CWHms1" , 
X_sub <- X_train[!BGC %in% badbgcs,]
```


The new rebalanced training set is 310 668 points. This training set is submitted to ranger to generate a final climate model of BGCs for western north america.

```{r final training sets}
X_sub <- as.data.frame(X_sub)
X2 <- removeOutlier(X_sub, alpha = .025, numIDvars = 1) ###set alpha for removal of outliers (2.5% = 3SD)
```

```{r remove very small units}
BGC_good <- rmLowSampleBGCs(X2) |>
  Cache(.)
```

```{r balance}
BGCbalance_recipe <- recipe(BGC ~ ., data =  BGC_good) |>
  step_downsample(BGC, under_ratio = 90) |>
  step_smote(BGC, over_ratio = .1, neighbors = 8) |> 
  prep()

X_balanced <- BGCbalance_recipe |>
  juice()

setDT(X_balanced)
BGC_Nums <- X_balanced[,.(Num = .N), by = BGC]   ## this is not being used.
```

```{r train model}
BGC_good[, BGC := as.factor(BGC)]

BGCmodel <- ranger(
  BGC ~ .,
  data = BGC_good,
  num.trees = 501,
  splitrule =  "extratrees",
  mtry = 4,
  min.node.size = 2,
  importance = "permutation",
  write.forest = TRUE,
  classification = TRUE,
  probability = FALSE
) |>
  Cache(.)
```
